{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, ifrelu, dropout):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.ifrelu = ifrelu\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.1)\n",
    "        self.conv2.weight.data.normal_(0, 0.1)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return out+res\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=4, dropout=0.1):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            ifrelu = False if i==(len(num_channels)-1) else True\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, ifrelu=ifrelu, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3430: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3571: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  return std(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "result = pd.read_csv('drive/MyDrive/1_before2016.csv')\n",
    "data = result.drop('meanest', axis=1)\n",
    "x = data.drop('actual', axis=1)\n",
    "mean_normal = np.mean(x, axis=0)\n",
    "std_normal = np.std(x, axis=0)\n",
    "data.loc[:, 'actq':'fincfy'] = (x - mean_normal)/std_normal\n",
    "\n",
    "xseq = []\n",
    "yseq = []\n",
    "for name, content in data.groupby('tic'):\n",
    "    for i in range(len(content.index)-10):\n",
    "        train_seq = []\n",
    "        train_label = []\n",
    "        for j in range(i, i + 10):\n",
    "            train_seq.append(content.iloc[j]['actual'])\n",
    "        for j in range(i+1, i + 11):\n",
    "            train_label.append(content.iloc[j]['actual'])\n",
    "        xseq.append(train_seq)\n",
    "        yseq.append(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = pd.read_csv('drive/MyDrive/1_after2016.csv')\n",
    "data1 = result1.drop('meanest', axis=1)\n",
    "x1 = data1.drop('actual', axis=1)\n",
    "data1.loc[:, 'actq':'fincfy'] = (x1 - mean_normal)/std_normal\n",
    "\n",
    "xseqt = []\n",
    "yseqt = []\n",
    "for name, content in data1.groupby('tic'):\n",
    "    for i in range(len(content.index)-10):\n",
    "        train_seq = []\n",
    "        train_label = []\n",
    "        for j in range(i, i + 10):\n",
    "            train_seq.append(content.iloc[j]['actual'])\n",
    "        for j in range(i+1, i + 11):\n",
    "            train_label.append(content.iloc[j]['actual'])\n",
    "        xseqt.append(train_seq)\n",
    "        yseqt.append(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "model = TemporalConvNet(num_inputs=10, num_channels=[1, 16, 16, 10])\n",
    "\n",
    "train = [(xseq[i], yseq[i]) for i in range(len(xseq))]\n",
    "random.shuffle(train)\n",
    "\n",
    "N = len(xseq)\n",
    "train_N = (int(N/64)-20) * 64\n",
    "valid_N = N - train_N\n",
    "\n",
    "train_x = torch.FloatTensor([train[i][0] for i in range(train_N)])\n",
    "train_x = train_x.reshape(train_x.shape[0], -1, 1)\n",
    "train_y = torch.FloatTensor([train[i][1] for i in range(train_N)])\n",
    "train_y = train_y.reshape(train_y.shape[0], -1, 1)\n",
    "\n",
    "valid_x = torch.FloatTensor([train[i][0] for i in range(train_N, N)])\n",
    "valid_x = valid_x.reshape(valid_x.shape[0], -1, 1)\n",
    "valid_y = torch.FloatTensor([train[i][1] for i in range(train_N, N)])\n",
    "valid_y = valid_y.reshape(valid_y.shape[0], -1, 1)\n",
    "\n",
    "test_x = torch.FloatTensor(xseqt)\n",
    "test_x = test_x.reshape(test_x.shape[0], -1, 1)\n",
    "test_y = torch.FloatTensor(yseqt)\n",
    "test_y = test_y.reshape(test_y.shape[0], -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minloss = 0.08\n",
    "for epoch in range(1000):\n",
    "    total_loss = 0\n",
    "    for step in range(int(train_x.shape[0]/64)):\n",
    "        # 生成数据\n",
    "        src = train_x[step*64 : (step*64+64)]\n",
    "        tgt = train_y[step*64 : (step*64+64)]\n",
    "        # 清空梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 进行transformer的计算\n",
    "        out = model(src)\n",
    "        \n",
    "        #print(out.contiguous().view(-1, out.size()[-1]))\n",
    "        #print(tgt_y.contiguous().view(-1, tgt_y.size()[-1]))\n",
    "        loss = criteria(out[:, -1, :], tgt[:, -1, :])\n",
    "        #print(loss)\n",
    "\n",
    "        # 计算梯度\n",
    "        loss.backward()\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss\n",
    "\n",
    "        # 每10次打印一下loss\n",
    "    if epoch % 10 == 0:\n",
    "      print(\"Epoch {}, train_loss: {}\".format(epoch, total_loss))\n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "            v_src = valid_x\n",
    "            v_tgt = valid_y\n",
    "            v_out = model(v_src)\n",
    "            v_loss = criteria(v_out[:, -1, :], v_tgt[:, -1, :])\n",
    "            if(v_loss < minloss):\n",
    "              minloss = v_loss\n",
    "              torch.save(model, 'drive/MyDrive/tcn.pth')\n",
    "            print(\"Epoch {}, valid_loss: {}\".format(epoch, v_loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def withinten(y_true, y_pred):\n",
    "    sum1 = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_pred[i] < 1.1*y_true[i] and y_pred[i] > 0.9*y_true[i]):\n",
    "            sum1+=1\n",
    "    return sum1/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def test(model, test_x, test_y):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      v_src = test_x\n",
    "      v_tgt_y = test_y\n",
    "      v_out = model(v_src)\n",
    "      v_loss = criteria(v_out[:, -1, :], v_tgt_y[:, -1, :]).item()\n",
    "      r2 = r2_score(v_tgt_y[:, -1, :], v_out[:, -1, :])\n",
    "      within10 = withinten(v_tgt_y[:, -1, :], v_out[:, -1, :])\n",
    "  return v_loss, r2, within10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, r2, within10 = test(model, test_x, test_y)\n",
    "loss, r2, within10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
